{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Technology Sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=data.columns[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_text', 'post_flair', 'post_additional_url', 'URL Text'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Movie prop used by Sir Richard Attenborough in the film Jurassic Park on view at the Amazing Amber ... [+] exhibition in Edinburgh, Scotland, in 2013.Somewhere in South America, a miner finds a piece of amber. Inside the hardened tree resin, he notes what seems to be a mosquito. Using advanced equipment, scientists extract the last meal of the blood-sucking insect. Thanks to the genetic code perfectly preserved in the still intact blood cells, the scientists then clone a dinosaur. The novel and later successful movie franchise \"Jurassic Park\" popularized the idea that amber could preserve soft tissue and even DNA-molecules over millions of years. But real attempts to extract DNA from amber or similar substances were unsuccessful to this day, and resin-embedded samples were deemed unsuitable for genetic examinations.Unlike in the movies, fossil tree resin is not a good choice to preserve DNA, a fragile molecule carrying genetic instructions for the development, functioning, growth and reproduction of all known organisms. When a viscous substance traps a small animal, the soft tissues start to decay immediately and most DNA is lost before the entire animal is even encapsulated. Even if some DNA is preserved, the resin\\'s chemical compounds will react with it, destroying it over time.A study published in the journal PLOS ONE attempted to determine if and how long the DNA of insects enclosed in resinous materials can be preserved. The researchers collected small ambrosia beetles that were trapped in the resin of amber trees (Hymenaea) in Madagascar. The chemical composition of this modern tree resin is very similar to fossilized amber. The samples were stored for 2 to 6 years and then processed.Tree resin with embedded ambrosia beetles.The study concluded that although it is very fragile, DNA was still preserved in the samples. First attempts using ethanol to dissolve the resin surrounding the beetles proved to be counterproductive. The alcohol reacts with the resin, destroying any DNA. This observation may explain why past attempts to extract DNA were always unsuccessful. Even after perfecting the extraction process switching chemicals, new problems emerged. The polymerase chain reaction (or PCR) is widely used to replicate small fragments of DNA, but the researchers discovered that this method is not very effective with DNA extracted from resinous materials. It is possible, so the authors, that substances found in the resin inhibit the chemicals used to copy single DNA strings. Only after carefully cleaning the samples and repeating the PCR-process various times, enough DNA was replicated to study the genomics of the embedded organism.It is still not clear just how long the DNA can survive inside the resin. The researchers will apply the new method to other examples of resin-embedded insects, from most recent to the oldest one, to determine the decay rate of DNA. Water also seems to play an essential role in the preservation potential. The resin creates a fully waterproof barrier, keeping moisture in the tissue. This could also affect the stability of the genetic material. Despite their optimism to add this type of analysis of fossil DNA to more common methods - like DNA recovered from skeletal material, mummified and frozen tissues - the researchers have no intention of raising dinosaurs.I\\'m a freelance geologist working mostly in the Eastern Alps. I graduated in 2007 with a project studying how permafrost, that¬¥s frozen soil, is reacting to the moreI\\'m a freelance geologist working mostly in the Eastern Alps. I graduated in 2007 with a project studying how permafrost, that¬¥s frozen soil, is reacting to the more visible recent changes of the alpine environment. Studying therefore old maps, photographs and reports, I became interested in the history of geology and how early geologists figured out how earth works, blogging about it in my spare time. Living in one of the classic areas of early geological research, I combine field trips with the historic maps, figures and research done there. But geology is more than a historic or local science, as geological forces shaped and still influence history worldwide.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['URL Text'][105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s\n",
    "\n",
    "data['post_text'] = data['post_text'].apply(lambda x:clean_text(x))\n",
    "data['URL Text'] = data['URL Text'].apply(lambda x:clean_text(x))\n",
    "\n",
    "flairs = data['post_flair'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Networking/Telecom', 'Social', 'Space', 'Robotics/Automation',\n",
       "       'Energy', 'Biotechnology', 'Society', 'Business', 'Transportation',\n",
       "       'Nanotech/Materials', 'Hardware', 'Software', 'Politics', 'Privacy',\n",
       "       'Crypto', 'Security', 'SECURITY', 'Machine', 'CRYPTO', 'PRIVACY',\n",
       "       'crypto', 'politics', 'software', 'artificial', 'POLITICS', 'HARDWARE',\n",
       "       'hardware', 'security'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticreg(X_train,y_train,X_test,y_test):\n",
    "    \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "  logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=1, C=100, penalty='l2')),\n",
    "                 ])\n",
    "  logreg.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = logreg.predict(X_test)\n",
    "\n",
    "  print(len(y_pred))\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    \n",
    "\n",
    "  return logreg\n",
    "#  print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train,y_train,X_test,y_test):\n",
    "  nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ])\n",
    "  nb.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = nb.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#  print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mlp\n",
    "def mlpclassifier(X_train,y_train,X_test,y_test):  \n",
    "  mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
    "                 ])\n",
    "  mlp.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = mlp.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#  print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbclassifier(X_train,y_train,X_test,y_test):  \n",
    "    xgb_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', XGBClassifier(random_state=42, seed=2, colsample_bytree=0.6,eval_metric='merror',subsample=0.7,objective='multi:softmax')),\n",
    "                 ])\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#    print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________\n",
      "\n",
      "Flair Detection using ALL THREE as feature\n",
      "164\n",
      "accuracy 0.6097560975609756\n"
     ]
    }
   ],
   "source": [
    "def train_test(X,y):\n",
    " \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
    "   \n",
    "#    print(\"Results of Logistic Regression\")\n",
    "    return logisticreg(X_train,y_train,X_test,y_test)\n",
    "#    print(\"Results of XGB\")\n",
    "#    xgbclassifier(X_train,y_train,X_test,y_test)\n",
    "#    print(\"Results of Naive Bayes\")\n",
    "#    nb_classifier(X_train,y_train,X_test,y_test)\n",
    "#    print(\"Results of MLP\")\n",
    "#    mlpclassifier(X_train,y_train,X_test,y_test)\n",
    "    \n",
    "cat = data['post_flair']\n",
    "V = data['URL Text']\n",
    "W = data['post_text']\n",
    "U = data['post_additional_url']\n",
    "\n",
    "#print(\"______________________________________________\\n\")\n",
    "#print(\"Flair Detection using URL link text as feature\")\n",
    "#train_test(U,cat)\n",
    "#print(\"Flair Detection using URL page text as feature\")\n",
    "#train_test(V,cat)\n",
    "#print(\"______________________________________________\\n\")\n",
    "#print(\"Flair Detection using title text as feature\")\n",
    "#train_test(W,cat)\n",
    "\n",
    "print(\"______________________________________________\\n\")\n",
    "print(\"Flair Detection using ALL THREE as feature\")\n",
    "model = train_test(U+W+V,cat)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       assist professor chemistri washington univers ...\n",
       "1                            üåäüç≠üåäüç≠üåäüç≠üåä rosal√≠a social media\n",
       "2       year fight depress final got courag post socia...\n",
       "3       controversi facial recognit startup clearview ...\n",
       "4       binanc smart chain centralis decentralis let d...\n",
       "                              ...                        \n",
       "1632    √ø√∏√ø√† jfifdoesn‚Äôt wanna friend block social med...\n",
       "1633    seen interest robot design year allow adventur...\n",
       "1634                                                 hack\n",
       "1635    walmart unveil new initi aim store fulfil bigg...\n",
       "1636    bank digit servic protect wealth cybersecur pr...\n",
       "Length: 1637, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V+W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalised_model.bin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'finalised_model.bin'\n",
    "joblib.dump(model,filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
